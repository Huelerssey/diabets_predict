import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


# funÃ§Ã£o que otimiza o carregamento dos dados
@st.cache_data
def carregar_dados():
    tabela = pd.read_pickle("arquivos_pkl/dataframe_modelado.pkl")
    return tabela

# funÃ§Ã£o que constroi a pÃ¡gina 2
def construcao_projeto():
    st.markdown("<h1 style='text-align: center;'>ğŸ“Œ ConstruÃ§Ã£o do Projeto ğŸ“Œ</h1>", unsafe_allow_html=True)
    st.write("---")

    st.header("ğŸ“Œ IntroduÃ§Ã£o")
    st.write("Neste projeto, decidimos usar o poder da ciÃªncia de dados para prever quem poderia ser mais suscetÃ­vel a desenvolver diabetes. Com a ajuda do machine learning, buscamos desenvolver um modelo preditivo que possa nos ajudar a identificar os indivÃ­duos em risco, permitindo intervenÃ§Ãµes precoces e talvez atÃ© mesmo a prevenÃ§Ã£o da doenÃ§a.")
    st.image("imagens/1.jpg")
    st.write("---")

    st.header("ğŸ“Œ ObtenÃ§Ã£o dos dados")
    st.write("Nosso ponto de partida foi um conjunto de dados disponÃ­vel no Kaggle que contÃ©m informaÃ§Ãµes mÃ©dicas e comportamentais de indivÃ­duos e pode ser acessado atravÃ©s deste [link](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset). AtravÃ©s dessas caracteristicas, vamos ser capazes de prever se o paciente pode ou nÃ£o ter a doenÃ§a e qual a porcentagem disso acontecer.")
    st.write("---")

    st.header("ğŸ“Œ Entendimento da Ã¡rea/negÃ³cio")
    st.write("Vamos comeÃ§ar entendendo a base de dados, aqui estÃ¡ uma tabela com as 10 primeiras linhas do nosso dataset.")
    st.dataframe(carregar_dados().head(10), hide_index=True)
    st.write("gender: Sexo do paciente;")
    st.write("hypertension: Indica se o paciente tem hipertensÃ£o (1 para sim, 0 para nÃ£o);")
    st.write("heart_disease: Indica se o paciente tem doenÃ§a cardÃ­aca (1 para sim, 0 para nÃ£o);")
    st.write("smoking_history: HistÃ³rico de fumo do paciente (nunca, atual, ex-fumante, etc);")
    st.write("bmi: Ãndice de Massa Corporal do paciente. O BMI Ã© uma medida que tenta quantificar a quantidade de tecido muscular, gordura e osso de um indivÃ­duo, e categoriza esse indivÃ­duo como subpeso, peso normal, sobrepeso ou obeso com base nesse valor;")
    st.write("HbA1c_level: NÃ­vel de Hemoglobina Glicada (HbA1c) no sangue do paciente. A hemoglobina glicada Ã© uma forma de hemoglobina que estÃ¡ ligada quimicamente a um aÃ§Ãºcar. O nÃ­vel de HbA1c no sangue de uma pessoa pode indicar o nÃ­vel mÃ©dio de aÃ§Ãºcar no sangue em um perÃ­odo de semanas/meses;")
    st.write("blood_glucose_level: NÃ­vel de glicose no sangue do paciente;")
    st.write("diabetes: Indica se o paciente tem diabetes (1 para sim, 0 para nÃ£o).")
    st.write("---")

    st.header("ğŸ“Œ Limpeza e tratamento dos dados")
    st.write("Antes de poder mergulhar de cabeÃ§a na anÃ¡lise, temos que garantir que nossos dados estejam limpos e prontos para uso. Isso incluiu a remoÃ§Ã£o de linhas duplicadas e a exclusÃ£o de registros que nÃ£o continham informaÃ§Ãµes suficientes, transformar ou deletar dados irrelevantes e etc...")
    codigo0 = """
    # verificando dados da tabela
    print(tabela.info())
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 100000 entries, 0 to 99999
    Data columns (total 9 columns):
    #   Column               Non-Null Count   Dtype  
    ---  ------               --------------   -----  
    0   gender               100000 non-null  object 
    1   age                  100000 non-null  float64
    2   hypertension         100000 non-null  int64  
    3   heart_disease        100000 non-null  int64  
    4   smoking_history      100000 non-null  object 
    5   bmi                  100000 non-null  float64
    6   HbA1c_level          100000 non-null  float64
    7   blood_glucose_level  100000 non-null  int64  
    8   diabetes             100000 non-null  int64  
    dtypes: float64(3), int64(4), object(2)
    """
    st.code(codigo0, language='python')
    st.write("Ã‰ importante notar que a etapa de limpeza de dados em um projeto de ciÃªncia de dados geralmente nÃ£o Ã© um processo linear. Frequentemente, pode ser necessÃ¡rio retornar a esta fase para ajustar ou remodelar os dados Ã  medida que surgem novas necessidades ao longo do projeto. Felizmente, neste caso, o conjunto de dados que temos jÃ¡ veio relativamente limpo. Isso nos poupa tempo significativo e nos permite concentrar nossos esforÃ§os nas prÃ³ximas etapas.")

    codigo1 = """
    # deleta colunas duplicadas
    tabela = tabela.drop_duplicates()

    # remove os valores nÃ£o significativos da coluna genero
    tabela = tabela[tabela["gender"] != 'Other']

    # remove os pacientes com registro nÃ£o informado sobre tabagismo
    tabela = tabela[tabela["smoking_history"] != 'No Info']
    """
    st.code(codigo1, language="python")

    st.write("Como o nosso modelo de inteligÃªncia artificial nÃ£o Ã© capaz de trabalhar com texto diretamente, tambÃ©m convertemos os dados categÃ³ricos em numÃ©ricos para facilitar o uso posterior.")
    codigo2 = """
    # Inicializa o label encoder
    le = LabelEncoder()

    # reajusta as colunas de texto para nÃºmeros
    tabela['gender'] = le.fit_transform(tabela['gender'])
    tabela['smoking_history'] = le.fit_transform(tabela['smoking_history'])
    """
    st.code(codigo2, language="python")
    st.write("---")

    st.header("ğŸ“Œ AnÃ¡lise exploratÃ³ria de dados")
    st.write("Nesta etapa, queremos entender como as diferentes variÃ¡veis estÃ£o correlacionadas com a diabetes. Nosso objetivo Ã© identificar quais fatores sÃ£o os mais influentes na previsÃ£o da doenÃ§a. AlÃ©m disso, usamos vÃ¡rias visualizaÃ§Ãµes para entender a distribuiÃ§Ã£o de nossos dados, identificar possÃ­veis outliers e verificar se existe algum desequilÃ­brio em nossa variÃ¡vel de destino.")
    st.write("Pessoalmente gosto de dedicar uma seÃ§Ã£o inteira para a construÃ§Ã£o das funÃ§Ãµes que auxiliarÃ£o nas anÃ¡lises e na visualizaÃ§Ã£o de grÃ¡ficos. Desta forma, antes de aplicÃ¡-las aos dados, garantimos uma organizaÃ§Ã£o e padronizaÃ§Ã£o rigorosas no projeto.")
    codigo3 = """
    ## FUNÃ‡Ã•ES AUXILIARES ##

    # grÃ¡fico de correlaÃ§Ã£o dos dados com a diabetes
    correlacao = tabela.corr()[['diabetes']]
    correlacao_organizada = correlacao.sort_values(by='diabetes', ascending=False)
    plt.figure(figsize=(18, 7))
    sns.heatmap(correlacao_organizada, cmap="Blues", annot=True, fmt='.0%')
    plt.show()

    # funÃ§Ã£o que retorna todos os valores Ãºnicos de uma coluna
    def verificar_val_unicos(dataframe):
        valores_unicos = {}
        for col in dataframe.columns:
            valores_unicos[col] = list(dataframe[col].unique())
        for col, vals in valores_unicos.items():
            print(f"{col}: {vals}")
        return valores_unicos

    # retorna o limite inferior e o limite superior
    def limites(coluna):
        q1 = coluna.quantile(0.25)
        q3 = coluna.quantile(0.75)
        amplitude = q3 - q1
        return (q1 - 1.5 * amplitude, q3 + 1.5 * amplitude)

    # plota 2 grÃ¡ficos sendo o primeiro com os outliers e o segundo, sem
    def box_plot(coluna):
        fig, (ax1, ax2) = plt.subplots(1, 2)
        fig.set_size_inches(15,5)
        sns.boxplot(x=coluna, ax=ax1)
        ax2.set_xlim(limites(coluna))
        sns.boxplot(x=coluna, ax=ax2)
        return plt.show()

    # plota um grÃ¡fico de histograma
    def histograma(coluna):
        plt.figure(figsize=(15, 5))
        sns.histplot(coluna, kde=True)
        return plt.show()

    # plota um grÃ¡fico de pizza
    def grafico_pizza(coluna):
        plt.figure(figsize=(10, 6))
        coluna.value_counts().plot(kind='pie', autopct='%1.1f%%')
        plt.ylabel('')
        return plt.show()
    
    # plota um grÃ¡fico de contagem
    def countplot(coluna):
    plt.figure(figsize=(10, 6))
    sns.countplot(x=coluna, data=tabela)
    plt.ylabel('')
    return plt.show()

    # cada coluna do dataframe terÃ¡ os grÃ¡ficos plotados
    def plot_all_columns(df):
        for col in df.columns:
            print(f"Coluna: {col}")
            box_plot(df[col])
            histograma(df[col])
            grafico_pizza(df[col])
            countplot(df[col])

    # Exclui outliers e retorna o novo dataframe e tambÃ©m a quantidade de linhas removidas
    def excluir_outliers(df, nome_coluna):
        qtde_linhas = df.shape[0]
        lim_inf, lim_sup = limites(df[nome_coluna])
        df = df.loc[(df[nome_coluna] >= lim_inf) & (df[nome_coluna] <= lim_sup), : ]
        linhas_removidas = qtde_linhas - df.shape[0]
        return df, linhas_removidas
    """
    st.code(codigo3, language='python')
    st.write("Com todas as funÃ§Ãµes construidas, vamos colocar a mÃ£o na massa nas anÃ¡lises!")
    
    st.write("---")
    st.write("")
    st.write("**GrÃ¡fico de calor** - para correlaÃ§Ã£o entre as caracterÃ­sticas e a variÃ¡vel de resultado diabetes. As cores mais escuras indicam uma correlaÃ§Ã£o positiva mais forte.")
    
    # titulo do grÃ¡fico
    st.subheader('CorrelaÃ§Ã£o das caracteristicas com a Diabetes')

    # cacula a correlaÃ§Ã£o
    correlation = carregar_dados().corr()[['diabetes']]
    correlation_sorted = correlation.sort_values(by='diabetes', ascending=False)
    
    # Calculate percentage and add % symbol
    correlation_percent = correlation_sorted * 100
    annotations = correlation_percent.applymap(lambda x: f'{x:.0f}%')

    # cria um grÃ¡fico de calor
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.heatmap(correlation_sorted, cmap="Blues", annot=annotations, fmt='', ax=ax)
    st.pyplot(fig)
    st.write("")

    st.write("---")
    st.write("")
    st.write("")
    st.write("")
    # variÃ¡veis categÃ³ricas
    st.write("**GrÃ¡ficos de barras para variÃ¡veis categÃ³ricas** - Esses grÃ¡ficos mostram a distribuiÃ§Ã£o das variÃ¡veis categÃ³ricas 'gender', 'smoking_history' e 'diabetes'. Podemos ver quantas observaÃ§Ãµes temos para cada categoria.")
    
    # cria 3 colunas
    col1, col2, col3 = st.columns(3)

    # conteiner para organizaÃ§Ã£o
    with st.container():

        # grafico de distribuiÃ§Ã£o para diabetes
        col1.subheader("DistribuiÃ§Ã£o de diabetes")
        fig, ax = plt.subplots(figsize=(5, 4.06))
        sns.countplot(x='diabetes', data=carregar_dados(), ax=ax)
        col1.pyplot(fig)
        st.write("")

        # grÃ¡fico de distribuiÃ§Ã£o para 'gender'
        col2.subheader('DistribuiÃ§Ã£o de gÃªnero')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.countplot(x='gender', data=carregar_dados(), ax=ax)
        col2.pyplot(fig)
        st.write("")

        # grÃ¡fico de distribuiÃ§Ã£o para 'smoking_history'
        col3.subheader('DistribuiÃ§Ã£o de tabagismo')
        fig, ax = plt.subplots(figsize=(5, 4.05))
        sns.countplot(x='smoking_history', data=carregar_dados(), ax=ax)
        col3.pyplot(fig)
        st.write("")

    st.write("---")
    st.write("")
    st.write("")
    st.write("")
    # vareÃ¡veis numÃ©ricas
    st.write("**Histogramas para variÃ¡veis numÃ©ricas** - Esses grÃ¡ficos mostram a distribuiÃ§Ã£o das variÃ¡veis numÃ©ricas 'idade', 'bmi', 'HbA1c_level' e 'blood_glucose_level'. A linha suave (KDE) representa uma estimativa da densidade de probabilidade dos dados, que pode ser Ãºtil para identificar a forma da distribuiÃ§Ã£o dos dados.")

    # cria 2 colunas
    col1, col2 = st.columns(2)

    # conteiner para organizaÃ§Ã£o
    with st.container():

        # Histograma para 'age'
        col1.subheader('DistribuiÃ§Ã£o de idade por pacientes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.histplot(carregar_dados()['age'], bins=30, kde=True, ax=ax)
        col1.pyplot(fig)
        st.write("")

        # Histograma para 'bmi'
        col2.subheader('DistribuiÃ§Ã£o de IMC por pacientes')
        fig, ax = plt.subplots(figsize=(5, 4.1))
        sns.histplot(carregar_dados()['bmi'], bins=30, kde=True, ax=ax)
        col2.pyplot(fig)
        st.write("")

        # Histograma para 'HbA1c_level'
        col1.subheader('DistribuiÃ§Ã£o de hemoglobina glicada por pacientes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.histplot(carregar_dados()['HbA1c_level'], bins=30, kde=True, ax=ax)
        col1.pyplot(fig)
        st.write("")

        # Histograma para 'blood_glucose_level'
        col2.subheader('DistribuiÃ§Ã£o de nÃ­vel de glicose no sangue por pacientes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.histplot(carregar_dados()['blood_glucose_level'], bins=30, kde=True, ax=ax)
        col2.pyplot(fig)
        st.write("")

    st.write("---")
    st.write("")
    st.write("")
    st.write("")
    #variÃ¡veis numÃ©ricas
    st.write("**Box plots para variÃ¡veis numÃ©ricas por 'diabetes'** - Esses grÃ¡ficos mostram a distribuiÃ§Ã£o das variÃ¡veis numÃ©ricas divididas por 'diabetes'. Isso permite ver a diferenÃ§a na distribuiÃ§Ã£o dessas variÃ¡veis para pessoas com e sem diabetes, que nos auxilia a identificar outliers (valores extremos). Cada box plot mostra a mediana (a linha no meio da caixa), os quartis superior e inferior (as bordas da caixa) e os 'bigodes', que indicam a faixa dentro da qual a maioria dos dados se encontra.")

    # cria 2 colunas
    col1, col2 = st.columns(2)

    # conteiner para organizaÃ§Ã£o
    with st.container():

        # Boxplot para 'age'
        col1.subheader('DistribuiÃ§Ã£o de Idade por Diabetes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.boxplot(x='diabetes', y='age', data=carregar_dados(), ax=ax)
        col1.pyplot(fig)
        st.write("")

        # Boxplot para 'bmi'
        col2.subheader('DistribuiÃ§Ã£o de IMC por Diabetes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.boxplot(x='diabetes', y='bmi', data=carregar_dados(), ax=ax)
        col2.pyplot(fig)
        st.write("")

        # Boxplot para 'HbA1c_level'
        col1.subheader('DistribuiÃ§Ã£o de Hemoglobina glicada por Diabetes')
        fig, ax = plt.subplots(figsize=(5, 4))
        sns.boxplot(x='diabetes', y='HbA1c_level', data=carregar_dados(), ax=ax)
        col1.pyplot(fig)
        st.write("")

        # Boxplot para 'blood_glucose_level'
        col2.subheader('DistribuiÃ§Ã£o de NÃ­vel de glicose no sangue por Diabetes')
        fig, ax = plt.subplots(figsize=(5, 4.2))
        sns.boxplot(x='diabetes', y='blood_glucose_level', data=carregar_dados(), ax=ax)
        col2.pyplot(fig)
        st.write("")

    st.write("---")
    st.write("Nossa anÃ¡lise cuidadosa dos grÃ¡ficos nos levou a duas conclusÃµes cruciais. A primeira Ã© que a coluna do Ãndice de Massa Corporal (IMC) contÃ©m outliers - valores que se desviam significativamente do restante dos dados. Esses outliers precisarÃ£o ser tratados para evitar distorÃ§Ãµes em nossas futuras anÃ¡lises. A segunda conclusÃ£o Ã© que a nossa variÃ¡vel de resposta, 'diabetes', estÃ¡ desbalanceada. Esse desbalanceamento pode ser prejudicial para o desempenho do nosso modelo de aprendizado de mÃ¡quina, uma vez que ele poderia se tornar enviesado para a classe mais representada.")
    st.write("**Problema 1 - Outliers**: Uma questÃ£o-chave com o Ãndice de Massa Corporal (IMC) Ã© que ele nÃ£o reflete a distribuiÃ§Ã£o de gordura corporal, um aspecto essencial para avaliar o sobrepeso, um fator de risco para diabetes. O IMC nÃ£o diferencia entre massa magra (mÃºsculo) e massa gorda (gordura), que tÃªm implicaÃ§Ãµes de saÃºde muito diferentes. Considere dois indivÃ­duos, ambos com 1,70 m de altura e pesando 100 kg. Um Ã© fisiculturista e o outro leva um estilo de vida sedentÃ¡rio. Se calcularmos o IMC, ambos terÃ£o o mesmo resultado, indicando sobrepeso. No entanto, no caso do fisiculturista, esse fator especÃ­fico nÃ£o representa um risco para a sua saÃºde. Portanto, Ã© crucial levar em conta as limitaÃ§Ãµes do IMC ao usÃ¡-lo como indicador de saÃºde em nossa anÃ¡lise e por isso vamos excluir os valores discrepantes.")
    codigo4 = """
    #excluir outliers da coluna IMC
    tabela, linhas_removidas = excluir_outliers(tabela, 'bmi')
    print(f'{linhas_removidas} linhas removidas da coluna bmi')
    """
    st.code(codigo4, language='python')

    # cria duas colunas
    col1, col2 = st.columns(2)

    # conteiner
    with st.container():

        #coluna 1
        col1.write("**Problema 2 - Base desbalanceada**: Existem vÃ¡rias sub-categorias de problemas relacionadas ao desbalanceamento dos dados.")
        col1.write("**2.1 - ViÃ©s do Modelo**: Nosso modelo de aprendizado de mÃ¡quina pode se tornar enviesado para a classe majoritÃ¡ria, neste caso, indivÃ­duos nÃ£o diabÃ©ticos. Isso acontece porque o modelo tende a se ajustar mais aos dados que aparecem com mais frequÃªncia para minimizar o erro durante o treinamento. Como resultado, o modelo pode prever muito bem a classe majoritÃ¡ria, mas pode ter um desempenho ruim na previsÃ£o da classe minoritÃ¡ria (indivÃ­duos diabÃ©ticos).")
        col1.write("**2.2 - Dificuldade na avaliaÃ§Ã£o**: MÃ©tricas comuns de avaliaÃ§Ã£o de modelos, como acurÃ¡cia, podem ser enganosas quando os dados estÃ£o desbalanceados. Por exemplo, um modelo que simplesmente prevÃª que todos os indivÃ­duos sÃ£o nÃ£o diabÃ©ticos teria uma acurÃ¡cia de 88% na sua base de dados, embora nÃ£o seja Ãºtil para identificar indivÃ­duos diabÃ©ticos.")
        col1.write("**ResoluÃ§Ã£o**: Deu para perceber que Ã© crucial lidar com o desbalanceamento dos dados antes de treinar o modelo. Uma abordagem comum Ã© usar tÃ©cnicas de reamostragem para equilibrar as classes. Isso pode ser feito reduzindo a classe majoritÃ¡ria, aumentando a classe minoritÃ¡ria ou uma combinaÃ§Ã£o de ambas. Cada tÃ©cnica tem suas prÃ³prias limitaÃ§Ãµes e pode nÃ£o ser adequada para todos os conjuntos de dados ou problemas. Por este motivo, na etapa seguinte vamos explorar ao mÃ¡ximo a modelagem da base de dados para garantir a maior assertividade da nossa inteligÃªncia artificial ao tentar prever se um paciente tem ou nÃ£o diabetes, levando em consideraÃ§Ã£o os falsos positivos, falso negativos e a probabilidade estatÃ­stica para cada um deles.")

        #coluna 2
        # plota um grÃ¡fico de pizza
        fig, ax = plt.subplots(figsize=(5, 4))
        carregar_dados()['diabetes'].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=ax)
        ax.set_ylabel('')
        col2.pyplot(fig)
    
    st.write("---")

    st.header("ğŸ“Œ Modelando a inteligÃªncia artificial")
    st.write("Chegou a hora de construir nossos modelos. Experimentamos vÃ¡rios algoritmos de aprendizado de mÃ¡quina, incluindo Ãrvore de DecisÃ£o, Random Forest e Extra Trees. Conforme jÃ¡ explicado na etapa anterior, usamos diferentes mÃ©todos de reamostragem para lidar com o desequilÃ­brio em nossa variÃ¡vel de destino 'diabetes'. ApÃ³s treinar os modelos, avaliamos seu desempenho usando mÃ©tricas como a matriz de confusÃ£o, a pontuaÃ§Ã£o de recall e a acurÃ¡cia.")
    st.write("Novamente temos um toque pessoal em relaÃ§Ã£o a como construir um projeto de machine learning. Com o objetivo de manter uma organizaÃ§Ã£o padrÃ£o e a otimizaÃ§Ã£o do tempo de entrega, construo uma funÃ§Ã£o responsÃ¡vel por balancear, treinar, testar e avaliar todos os modelos de uma vez sÃ³! ApÃ³s obter os resultados, podemos nos concentrar na anÃ¡lise e escolha do melhor modelo que irÃ¡ subir para produÃ§Ã£o, ou seja, serÃ¡ utilizado pelo usuÃ¡rio final. Aqui estÃ¡ ela:")
    codigo5 = """
    # definindo dados de treino e de teste
    y = tabela['diabetes']
    x = tabela.drop('diabetes', axis=1)

    # dividindo a base entre treino e teste
    x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size=0.30, random_state=42, stratify=y)

    # funÃ§Ã£o para avaliar modelos
    def avaliar_modelos(modelos, x_treino, y_treino, x_teste, y_teste, resampling_methods):
        resultados = {}
        
        for nome, modelo in modelos.items():
            for resampling_method in resampling_methods:
                if resampling_method == 'Random Undersample':
                    rus = RandomUnderSampler(random_state=42)
                    x_res, y_res = rus.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Undersample ClusterCentroid':
                    cc = ClusterCentroids(estimator=MiniBatchKMeans(n_init=1, random_state=0), random_state=42)
                    x_res, y_res = cc.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Undersample NearMiss':
                    nm = NearMiss()
                    x_res, y_res = nm.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Random Oversample':
                    ros = RandomOverSampler(random_state=42, shrinkage=0.7)
                    x_res, y_res = ros.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Oversample SMOTE':
                    sm = SMOTE(random_state=42)
                    x_res, y_res = sm.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Oversample ADASYN':
                    ada = ADASYN(random_state=42)
                    x_res, y_res = ada.fit_resample(x_treino, y_treino)
                elif resampling_method == 'Combined Over/Undersample':
                    sme = SMOTEENN(random_state=42)
                    x_res, y_res = sme.fit_resample(x_treino, y_treino)
                else:
                    raise ValueError(f'MÃ©todo de resampling desconhecido: {resampling_method}')
                
                modelo.fit(x_res, y_res)
                y_pred = modelo.predict(x_teste)
                cm = confusion_matrix(y_teste, y_pred)
                rs = recall_score(y_teste, y_pred)
                sa = accuracy_score(y_teste, y_pred)
                
                if nome not in resultados:
                    resultados[nome] = {}
                
                resultados[nome][resampling_method] = {
                    'Matriz de confusÃ£o': cm,
                    'Recall': rs,
                    'AcurÃ¡cia': sa
                }
        
        return resultados

    # Criar o modelo de Ã¡rvore de decisÃ£o
    clf = tree.DecisionTreeClassifier(random_state=42)

    # Criar o modelo de Random Forest
    clfrf = RandomForestClassifier(random_state=42)

    # Criar o modelo de Extra Trees
    clfet = ExtraTreesClassifier(random_state=42)

    # Criar o dicionÃ¡rio com os nomes dos modelos e as instÃ¢ncias correspondentes
    modelos = {
        'Decision Tree': clf,
        'Random Forest': clfrf,
        'Extra Trees': clfet
    }

    # Definir os mÃ©todos de resampling a serem utilizados
    resampling_methods = ['Random Undersample', 'Undersample ClusterCentroid', 'Undersample NearMiss',
                        'Random Oversample', 'Oversample SMOTE', 'Oversample ADASYN',
                        'Combined Over/Undersample']

    # Chamar a funÃ§Ã£o para avaliar os modelos
    resultados = avaliar_modelos(modelos, x_treino, y_treino, x_teste, y_teste, resampling_methods)

    # Imprimir os resultados
    for nome, resultado in resultados.items():
        print(f"Modelo: {nome}")
        for resampling_method, res in resultado.items():
            print(f"MÃ©todo de resampling: {resampling_method}")
            print(f"Matriz de confusÃ£o: {res['Matriz de confusÃ£o']}")
            print(f"Recall: {res['Recall']:.2f}%")
            print(f"AcurÃ¡cia: {res['AcurÃ¡cia']:.2f}%")
    """
    st.code(codigo5, language='python')
    st.write("---")

    st.header("ğŸ“Œ ApresentaÃ§Ã£o de Resultados")
    st.write("Os resultados foram interessantes. Cada modelo e mÃ©todo de reamostragem teve seus pontos fortes e fracos. Em alguns casos, obtivemos um recall muito alto, mas uma acurÃ¡cia mais baixa. Em outros, a acurÃ¡cia era alta, mas o recall nÃ£o era tÃ£o impressionante. Para facilitar a visualizaÃ§Ã£o, disponibilizei todos eles a baixo. Utilize a legenda como guia e selecione o modelo desejado para ver seus resultados.")

    with st.container():

        #cria 3 colunas
        col1, col2, col3 = st.columns(3)

        # Lista de resultados
        lista_resultados = [
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Random Undersample',
                'matriz_confusao': [[14077, 2098], [249, 1606]],
                'recall': 0.87,
                'AcurÃ¡cia': 0.87
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Undersample ClusterCentroid',
                'matriz_confusao': [[11076, 5099], [56, 1799]],
                'recall': 0.97,
                'AcurÃ¡cia': 0.71
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Undersample NearMiss',
                'matriz_confusao': [[8536, 7639], [321, 1534]],
                'recall': 0.83,
                'AcurÃ¡cia': 0.56
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Random Oversample',
                'matriz_confusao': [[15499, 676], [458, 1397]],
                'recall': 0.75,
                'AcurÃ¡cia': 0.94
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Oversample SMOTE',
                'matriz_confusao': [[15461, 714], [471, 1384]],
                'recall': 0.75,
                'AcurÃ¡cia': 0.93
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Oversample ADASYN',
                'matriz_confusao': [[15497, 678], [487, 1368]],
                'recall': 0.74,
                'AcurÃ¡cia': 0.94
            },
            {
                'modelo': 'Decision Tree',
                'metodo_resampling': 'Combined Over/Undersample',
                'matriz_confusao': [[14931, 1244], [333, 1522]],
                'recall': 0.82,
                'AcurÃ¡cia': 0.91
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Random Undersample',
                'matriz_confusao': [[14373, 1802], [191, 1664]],
                'recall': 0.90,
                'AcurÃ¡cia': 0.89
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Undersample ClusterCentroid',
                'matriz_confusao': [[11500, 4675], [46, 1809]],
                'recall': 0.98,
                'AcurÃ¡cia': 0.74
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Undersample NearMiss',
                'matriz_confusao': [[10251, 5924], [375, 1480]],
                'recall': 0.80,
                'AcurÃ¡cia': 0.65
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Random Oversample',
                'matriz_confusao': [[15798, 377], [516, 1339]],
                'recall': 0.72,
                'AcurÃ¡cia': 0.95
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Oversample SMOTE',
                'matriz_confusao': [[15699, 476], [487, 1368]],
                'recall': 0.74,
                'AcurÃ¡cia': 0.95
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Oversample ADASYN',
                'matriz_confusao': [[15502, 673], [458, 1397]],
                'recall': 0.75,
                'AcurÃ¡cia': 0.94
            },
            {
                'modelo': 'Random Forest',
                'metodo_resampling': 'Combined Over/Undersample',
                'matriz_confusao': [[14926, 1249], [289, 1566]],
                'recall': 0.84,
                'AcurÃ¡cia': 0.91
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Random Undersample',
                'matriz_confusao': [[14305, 1870], [192, 1663]],
                'recall': 0.90,
                'AcurÃ¡cia': 0.89
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Undersample ClusterCentroid',
                'matriz_confusao': [[11885, 4290], [76, 1779]],
                'recall': 0.96,
                'AcurÃ¡cia': 0.76
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Undersample NearMiss',
                'matriz_confusao': [[11756, 4419], [368, 1487]],
                'recall': 0.80,
                'AcurÃ¡cia': 0.73
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Random Oversample',
                'matriz_confusao': [[15493, 682], [447, 1408]],
                'recall': 0.76,
                'AcurÃ¡cia': 0.94
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Oversample SMOTE',
                'matriz_confusao': [[15569, 606], [484, 1371]],
                'recall': 0.74,
                'AcurÃ¡cia': 0.94
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Oversample ADASYN',
                'matriz_confusao': [[15335, 840], [452, 1403]],
                'recall': 0.76,
                'AcurÃ¡cia': 0.93
            },
            {
                'modelo': 'Extra Trees',
                'metodo_resampling': 'Combined Over/Undersample',
                'matriz_confusao': [[14816, 1359], [283, 1572]],
                'recall': 0.85,
                'AcurÃ¡cia': 0.91
            },
        ]

        # OpÃ§Ãµes disponÃ­veis no seletor
        opcoes = [f"{resultado['modelo']} - {resultado['metodo_resampling']}" for resultado in lista_resultados]

        # coluna do meio
        with col2:
            st.write("InteligÃªncia Artificial - MÃ©todo de Reajuste da Base de Dados")
            # Seletor de opÃ§Ãµes
            opcao_selecionada = st.selectbox("Selecione uma opÃ§Ã£o:", opcoes)

    with st.container():

        #cria 3 colunas
        col1, col2 = st.columns(2)

        # Encontrar o resultado correspondente Ã  opÃ§Ã£o selecionada
        resultado_selecionado = None
        for resultado in lista_resultados:
            if f"{resultado['modelo']} - {resultado['metodo_resampling']}" == opcao_selecionada:
                resultado_selecionado = resultado
                break

        # Verificar se um resultado vÃ¡lido foi selecionado
        if resultado_selecionado is not None:
            # Dados da matriz de confusÃ£o
            matriz_confusao = resultado_selecionado['matriz_confusao']

            # Cores das fatias para cada grÃ¡fico
            cores_fatias1 = ['#00FF00', '#FF0000']
            cores_fatias2 = ['#FF0000', '#00FF00']

            # Legendas
            legenda1 = ['Errou - Modelo nÃ£o classificou o paciente como DiabÃ©tico', 'Acertou - Modelo classificou o paciente como DiabÃ©tico']
            legenda2 = ['Acertou - Modelo nÃ£o classificou o paciente como DiabÃ©tico', 'Errou - Modelo classificou o paciente como DiabÃ©tico']

            col1.subheader("Tentando prever Pacientes que eram DiabÃ©ticos")
            # GrÃ¡fico dos dados que eram Diabetes
            plt.figure(figsize=(10, 10))
            plt.pie(matriz_confusao[1], colors=cores_fatias2, autopct='%1.1f%%', startangle=90)
            plt.legend(legenda1, loc='upper left', bbox_to_anchor=(0.80, 0.80), bbox_transform=plt.gcf().transFigure)
            plt.axis('equal')

            # Exibir o grÃ¡fico no Streamlit
            col1.pyplot(plt)

            col2.subheader("Tentando prever Pacientes que nÃ£o eram DiabÃ©ticos")
            # GrÃ¡fico dos dados que nÃ£o eram Diabetes
            plt.figure(figsize=(10, 10.15))
            plt.pie(matriz_confusao[0], colors=cores_fatias1, autopct='%1.1f%%', startangle=90)
            plt.legend(legenda2, loc='upper left', bbox_to_anchor=(0.80, 0.80), bbox_transform=plt.gcf().transFigure)
            plt.axis('equal')

            # Exibir o grÃ¡fico no Streamlit
            col2.pyplot(plt)
            st.write(f"AcurÃ¡cia: {resultado_selecionado['AcurÃ¡cia']*100}% - A porcentagem total de previsÃµes que o modelo acertou;")
            st.write(f"Recall: {resultado_selecionado['recall']*100}% - A porcentagem de pacientes verdadeiramente diabÃ©ticos que foram corretamente identificados pelo modelo.")
    st.write("---")

    st.header("ğŸ“Œ Escolhendo o melhor Modelo e colocando em ProduÃ§Ã£o")
    st.write("Com todos os resultados em mÃ£os, escolhemos o modelo Random Forest com o mÃ©todo de subamostragem Random Under Sampler. Esse modelo ofereceu um bom equilÃ­brio entre recall e acurÃ¡cia, tornando-o uma escolha sÃ³lida para nossa aplicaÃ§Ã£o. Treinamos o modelo final com todo o conjunto de dados, e agora ele estÃ¡ pronto para ser usado para prever se um indivÃ­duo pode desenvolver diabetes e qual a probabilidade disso acontecer.")
    st.write("Aqui estÃ¡ o cÃ³digo do modelo responsÃ¡vel pelas previsÃµes:")
    codigo6 = """
    # definindo dados de treino e de teste
    y = tabela['diabetes']
    x = tabela.drop('diabetes', axis=1)

    # dividindo a base entre treino e teste
    x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, random_state=42, stratify=y)

    # Criar o modelo de Random Forest
    clf = RandomForestClassifier(random_state=42)

    # Instanciar o RandomUnderSampler
    rus = RandomUnderSampler(random_state=42)

    # Aplicar o resampling
    x_res, y_res = rus.fit_resample(x_treino, y_treino)

    # treina o modelo
    clf.fit(x_res, y_res)

    # testa o modelo
    y_pred = clf.predict(x_teste)

    # obtendo a probabilidade de ser da classe 1 (diabetes)
    prob_diabetes = clf.predict_proba(x_teste)[:, 1]

    # colocando modelo para produÃ§Ã£o
    joblib.dump(clf, "modelo_treinado.pkl")
    """
    st.code(codigo6, language='python')

    st.write("E aqui estÃ¡ o cÃ³digo responsÃ¡vel por captar as respostas do usuÃ¡rio que serÃ£o entregues ao modelo para que ele possa ser capaz de prever:")
    codigo7 = """
    # Carregar o modelo treinado
    clf = joblib.load("arquivos_pkl/modelo_treinado.pkl")

    # FunÃ§Ã£o para fazer previsÃµes
    def predict_diabetes(model, patient_info):
        prediction = model.predict(patient_info)
        prediction_proba = model.predict_proba(patient_info)[0, int(prediction[0])]
        return prediction, prediction_proba

    # Mapeamento da coluna gender
    gender_mapping = {
        'Homem': 0,
        'Mulher': 1
    }
    gender = st.selectbox('GÃªnero', list(gender_mapping.keys()))
    gender = gender_mapping[gender]  # Converter para o cÃ³digo correspondente

    # idade
    age = st.number_input('Idade', min_value=0, max_value=100)

    # Mapeamento para as colunas hypertension e heart_disease
    binary_mapping = {
        'NÃ£o': 0,
        'Sim': 1
    }
    hypertension = st.selectbox('HipertensÃ£o', list(binary_mapping.keys()))
    hypertension = binary_mapping[hypertension]  # Converter para o cÃ³digo correspondente
    heart_disease = st.selectbox('DoenÃ§a CardÃ­aca', list(binary_mapping.keys()))
    heart_disease = binary_mapping[heart_disease]  # Converter para o cÃ³digo correspondente

    # Mapeamento da coluna smoking_history
    smoking_mapping = {
        'Nunca fumou': 3,
        'Fumante frequente': 0,
        'Ex-fumante': 2,
        'Pelo menos uma vez': 1,
        'Fumante ocasional': 4
    }
    smoking_history = st.selectbox('HistÃ³rico de Fumante', list(smoking_mapping.keys()))
    smoking_history = smoking_mapping[smoking_history]  # Converter para o cÃ³digo correspondente

    #IMC
    bmi = st.number_input('IMC', min_value=0.0)

    #nivel de hemoglobina glicada
    HbA1c_level = st.number_input('NÃ­vel de HbA1c', min_value=0.0)

    #nivel de glicose
    blood_glucose_level = st.number_input('NÃ­vel de Glicose no Sangue', min_value=0)

    # BotÃ£o para fazer previsÃ£o
    if st.button('Fazer previsÃ£o'):
        # Preparar os dados para a previsÃ£o
        patient_info = pd.DataFrame(np.array([[gender, age, hypertension, heart_disease, smoking_history, bmi, HbA1c_level, blood_glucose_level]]),
                                    columns=['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level'])

        # Fazer a previsÃ£o
        prediction, prediction_proba = predict_diabetes(clf, patient_info)
        if prediction[0] == 1:
            st.success(f'O modelo classificou o paciente como diabÃ©tico com {prediction_proba*100:.2f}% de chance de acerto.')
        else:
            st.success(f'O modelo classificou o paciente como nÃ£o diabÃ©tico com {prediction_proba*100:.2f}% de chance de acerto.')
    """
    st.code(codigo7, language='python')
    st.write("---")

    #footer
    with st.container():
        col1, col2, col3 = st.columns(3)
        
        col2.write("Developed By: [@Huelerssey](https://github.com/Huelerssey)")